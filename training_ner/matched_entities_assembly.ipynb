{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04b40c6-498f-44d6-8c23-98d413bd46f1",
   "metadata": {},
   "source": [
    "## Model to do\n",
    "\n",
    "- Try to build a model that handles the word splits better\n",
    "- Build a simple matcher that generates example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eea7bfcc-963a-44ac-b1f5-7df2507bbdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3256c9e3-48cd-4bf1-a550-d17358aadbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48f740d0-3489-41aa-9b66-690b8eb661eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    \n",
    "    def __init__(self, model_name = \"paraphrase-albert-small-v2\"):\n",
    "        \n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def vectorize_list(self, input_list):\n",
    "        \n",
    "        embedding_matrix = self.model.encode(input_list)\n",
    "        \n",
    "        return embedding_matrix\n",
    "    \n",
    "    def vectorize_single(self, input_string):\n",
    "        \n",
    "        embedding_vector = self.model.encode([input_string])\n",
    "        \n",
    "        return embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fabd6a78-196f-4b85-bc23-18953b3eab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-case-finetuned-app-ner\")\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-case-finetuned-app-ner-tok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bb7accf-95dd-411b-b9ad-e26a5c467b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_dict = loaded_model.config.id2label\n",
    "label2id_dict = loaded_model.config.label2id\n",
    "model_label_2_id = {v:k for k,v in id2label_dict.items()}\n",
    "model_id_2_label = {v:k for k,v in label2id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b252bfac-44fe-4f64-82aa-999d1019130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipe = pipeline(\"ner\", aggregation_strategy=\"max\", model=loaded_model,tokenizer=loaded_tokenizer)\n",
    "feature_pipe = pipeline(\"feature-extraction\", model=loaded_model,tokenizer=loaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "075e1b9e-5ae9-4501-aa92-b44176a54173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matching_dictionary(matcher, DATA_PATH = \"data\"):\n",
    "    \n",
    "    matching_dict = {\"APP\":{},\"CAT\":{},\"PLAT\":{},\"REG\":{},\"MET\":{}}\n",
    "    \n",
    "    app_matcher = pd.read_csv(os.path.join(DATA_PATH,\"app_matching.csv\"))\n",
    "    matching_phrases = app_matcher[\"matching_phrase\"].tolist()\n",
    "    app_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"APP\"][\"embedding\"] = app_embedding_matrix\n",
    "    matching_dict[\"APP\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    metric_matcher = pd.read_csv(os.path.join(DATA_PATH,\"metric_matching.csv\"))\n",
    "    matching_phrases = metric_matcher[\"metric_name\"].tolist()\n",
    "    matching_type = metric_matcher[\"metric_type\"].tolist()\n",
    "    metric_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"MET\"][\"embedding\"] = metric_embedding_matrix\n",
    "    matching_dict[\"MET\"][\"matching_list\"] = matching_phrases\n",
    "    matching_dict[\"MET\"][\"metric_type\"] = matching_type\n",
    "    \n",
    "    platform_matcher = pd.read_csv(os.path.join(DATA_PATH,\"platform_matching.csv\"))\n",
    "    matching_phrases = platform_matcher[\"matching_phrase\"].tolist()\n",
    "    platform_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"PLAT\"][\"embedding\"] = platform_embedding_matrix\n",
    "    matching_dict[\"PLAT\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    region_matcher = pd.read_csv(os.path.join(DATA_PATH,\"region_matching.csv\"))\n",
    "    matching_phrases = region_matcher[\"matching_phrase\"].tolist()\n",
    "    region_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"REG\"][\"embedding\"] = region_embedding_matrix\n",
    "    matching_dict[\"REG\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    category_matcher = pd.read_csv(os.path.join(DATA_PATH,\"category_matching.csv\"))\n",
    "    matching_phrases = category_matcher[\"matching_phrase\"].tolist()\n",
    "    category_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"CAT\"][\"embedding\"] = category_embedding_matrix\n",
    "    matching_dict[\"CAT\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    return matching_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8fb0b60d-3c4a-4423-8d59-5eadb55a8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8cfe8d6-619d-417f-be07-aa91a3e1c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dict = generate_matching_dictionary(matcher,DATA_PATH=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "eec05735-d8dc-4a56-a3b9-eed622b2b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMatchSelector(object):\n",
    "    \n",
    "    def __init__(self,ent_type,matcher_frame):\n",
    "        \n",
    "        self.ent_type = ent_type\n",
    "        \n",
    "        if isinstance(matcher_frame,pd.DataFrame):\n",
    "            self.raw_probs = 1 - np.array(matcher_frame[\"score\"])\n",
    "            probs = self.raw_probs**2\n",
    "            self.probs = probs/np.sum(probs)\n",
    "            self.match_list = matcher_frame[\"match\"].tolist()\n",
    "            \n",
    "            if self.ent_type == \"MET\":\n",
    "                metric_types = matcher_frame[\"type\"].tolist()\n",
    "                self.match_list = [(m,t) for m,t in zip(self.match_list,metric_types)]\n",
    "        else:\n",
    "            self.match_list = None\n",
    "            \n",
    "    def return_matches(self,ndraws=5):\n",
    "                                      \n",
    "        if self.match_list:\n",
    "            matches = self.match_list[:2]\n",
    "            return matches + [self.match_list[i] for i in np.random.choice(np.arange(len(self.match_list)),size=ndraws-2,replace=True,p=self.probs)]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def construct_example_sentences(input_sentence,all_matches,vectorizer,nmatch=5):\n",
    "    \n",
    "    sentences = {}\n",
    "    \n",
    "    # there must be a metric match\n",
    "    metric_comps = all_matches[\"MET\"][\"matches_for_sentence\"]\n",
    "    \n",
    "    if len(metric_comps) == 0:\n",
    "        # no matches\n",
    "        return {}, []\n",
    "    \n",
    "    # deal with category match\n",
    "    if len(all_matches[\"CAT\"][\"ner_match\"]) > 0: \n",
    "        has_category = True\n",
    "        category_comps = all_matches[\"CAT\"][\"matches_for_sentence\"]\n",
    "    else:\n",
    "        has_category = False\n",
    "        \n",
    "    # deal with app match\n",
    "    if len(all_matches[\"APP\"][\"ner_match\"]) > 0:\n",
    "        has_app = True\n",
    "    else:\n",
    "        has_app = False\n",
    "    \n",
    "        \n",
    "    for sent_id in range(nmatch):\n",
    "        sent = ''\n",
    "        valid_sent = True\n",
    "        sent_comps = {}\n",
    "        metric_name, metric_type = metric_comps[sent_id]\n",
    "        \n",
    "        # if we have app metric but not apps are present\n",
    "        if metric_type == \"app\" and not has_app:\n",
    "            valid_sent = False\n",
    "        \n",
    "        else:\n",
    "            sent += metric_name + \" \"\n",
    "            for ent_id, v in all_matches.items():\n",
    "                added_category = False \n",
    "                if (len(v[\"ner_match\"]) > 0) and (ent_id != \"MET\"):\n",
    "                    sent_comp = v[\"matches_for_sentence\"][sent_id]\n",
    "                \n",
    "                    # Where we have an app and a market level query, ensure that we make the query about a group of\n",
    "                    # apps. We can use the competitive set API for this, for example.\n",
    "                    if (ent_id == \"APP\") and (metric_type == \"market\"):\n",
    "                        #sent_comps[ent_id] = sent_comp + \" vs. its competitors\"\n",
    "                        #sent += sent_comp + \" vs. its competitors\"\n",
    "                        valid_sent = False\n",
    "                        pass\n",
    "                    # Where we have an app and a category, we want to remove the category\n",
    "                    elif (ent_id == \"CAT\") and has_app:\n",
    "                        valid_sent = False\n",
    "                        pass\n",
    "                    else:\n",
    "                        sent += sent_comp\n",
    "                    sent += \" \"\n",
    "        sent = sent.strip()\n",
    "        if valid_sent:\n",
    "            sentences[sent] = sent_comps\n",
    "        \n",
    "    if len(sentences) > 0:\n",
    "        \n",
    "        ## USE A SENTENCE TRANSFORMER MATCHER HERE SINCE WE ARE TRYING TO ORDER THE\n",
    "        ## OUTPUT BY MOST RELEVANT TO THE INPUT\n",
    "        \n",
    "        matched_sentences_embedding = vectorizer.vectorize_list(list(sentences.keys()))\n",
    "        input_sentence_embedding = vectorizer.vectorize_single(input_sentence)\n",
    "        sentence_ordering = np.argsort(distance.cdist(input_sentence_embedding,matched_sentences_embedding,metric=\"cosine\")[0])\n",
    "    \n",
    "        return sentences, [list(sentences.keys())[i] for i in sentence_ordering]\n",
    "    \n",
    "    else:\n",
    "        # no matches\n",
    "        return {}, []\n",
    "\n",
    "def extract_entities(model_output):\n",
    "\n",
    "    ents_data = {\"APP\":[],\"REG\":[],\"DATE\":[],\"PLAT\":[],\"MET\":[],\"CAT\":[]}\n",
    "    for ent in model_output[0]:\n",
    "        ent_id = model_label_2_id[ent['entity_group']]\n",
    "        ent_label = model_id_2_label[ent_id]\n",
    "    \n",
    "        if \"-\" in ent_label:\n",
    "            ent_label = ent_label.split(\"-\")[1]\n",
    "            ents_data[ent_label].append(ent[\"word\"])\n",
    "    \n",
    "    return ents_data\n",
    "\n",
    "\n",
    "def get_top_matches_to_ent(ents,match_dict,ent_type,nmatch=5):\n",
    "    \n",
    "    assert ent_type in [\"APP\", \"MET\", \"CAT\", \"REG\", \"PLAT\",\"DATE\"]\n",
    "    \n",
    "    if ent_type not in matching_dict:\n",
    "        return None\n",
    "    \n",
    "    # Doesn't work will for typos - need to use the ngram char matcher instead\n",
    "    # from the autocomplete matcher\n",
    "    \n",
    "    ents_to_match = ents[ent_type]\n",
    "    if len(ents_to_match) <= 2:\n",
    "        matched_ents = [\" \".join(ents_to_match)]\n",
    "    else:\n",
    "        matched_ents = [\" \".join(ents_to_match[:2]),\" \".join(ents_to_match[2:])]\n",
    "    \n",
    "    matched_dfs = []\n",
    "    \n",
    "    for matched_ent in matched_ents:\n",
    "        \n",
    "        ## USE A MATCHER THAT IS BETTER ABLE TO DEAL WITH TYPOS HERE\n",
    "        ## THIS IS FOR FUZZY MATCHING FROM THE EXTRACTED ENTITIES TO THE DBS\n",
    "        \n",
    "        matching_vector = matcher.vectorize_single(matched_ent)\n",
    "        distances = distance.cdist(matching_vector,matching_dict[ent_type][\"embedding\"],metric=\"cosine\")[0]\n",
    "        sorted_distances = np.argsort(distances)[:nmatch]\n",
    "        \n",
    "        print(matched_ent,min(distances))\n",
    "        if min(distances) < 0.6:\n",
    "            # attempt to prevent matches that are really poor\n",
    "        \n",
    "            closest_matches = [matching_dict[ent_type][\"matching_list\"][i] for i in sorted_distances]\n",
    "            if ent_type == \"MET\":\n",
    "                metric_types = [matching_dict[ent_type][\"metric_type\"][i] for i in sorted_distances]\n",
    "                matched_dfs.append(pd.DataFrame({\"query\":[matched_ent]*nmatch,\"match\":closest_matches,\"score\":distances[sorted_distances],\"type\":metric_types}))\n",
    "            else:\n",
    "                matched_dfs.append(pd.DataFrame({\"query\":[matched_ent]*nmatch,\"match\":closest_matches,\"score\":distances[sorted_distances]}))\n",
    "    \n",
    "    if matched_dfs:\n",
    "        return pd.concat(matched_dfs).sort_values(by=\"score\").reset_index(drop=True)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_matches(ents_data,match_dict):\n",
    "    \n",
    "    ents_matched_dict = {\"APP\":None,\"REG\":None,\"DATE\":None,\"PLAT\":None,\"MET\":None,\"CAT\":None}\n",
    "    \n",
    "    for ent, matches in ents_data.items():\n",
    "        \n",
    "        if len(matches) > 0:\n",
    "            matched_ents = get_top_matches_to_ent(ents_data,match_dict=matching_dict,ent_type=ent)\n",
    "            \n",
    "            if isinstance (matched_ents,type(None)):\n",
    "                # no matches \n",
    "                ents_matched_dict[ent] = {\n",
    "                    \"ner_match\":[], \n",
    "                    \"fuzzy_matches\":None, \n",
    "                    \"matches_for_sentence\":[]\n",
    "                }\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                match_selector = RandomMatchSelector(ent,matched_ents)\n",
    "                chosen_matches_for_sentence = match_selector.return_matches()\n",
    "        \n",
    "                ents_matched_dict[ent] = {\n",
    "                        \"ner_match\":matches, \n",
    "                        \"fuzzy_matches\":matched_ents, \n",
    "                        \"matches_for_sentence\":chosen_matches_for_sentence\n",
    "                }\n",
    "        \n",
    "        else:\n",
    "            # no matches\n",
    "            ents_matched_dict[ent] = {\n",
    "                    \"ner_match\":[], \n",
    "                    \"fuzzy_matches\":None, \n",
    "                    \"matches_for_sentence\":[]\n",
    "            }\n",
    "    \n",
    "    return ents_matched_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "cd6f5150-95ce-4544-ac1c-3fb44f35d0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blah blash 0.6878438266315849\n",
      "snapcht 0.34731029404777103\n",
      "france 7.439604488013174e-13\n",
      "ratings 5.472289288377397e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ratings snap france', 'ratings snap germany', 'reviews snapchat italy']"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"blah blash apps snapcht ratings in france\"\n",
    "# Get NER ents\n",
    "op = ner_pipe([query])\n",
    "# Extract thaen from the model output\n",
    "ents = extract_entities(op)\n",
    "# matches dictionary and their fuzzy matches\n",
    "all_matches = get_matches(ents,match_dict=matching_dict)\n",
    "# generate example sentences and then rank them - these will be the final matches\n",
    "sentences_map, ordered_sentences = construct_example_sentences(query,all_matches,vectorizer=matcher)\n",
    "ordered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "9bec8b7d-ee7e-4f1b-932c-08ee983f6880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APP': {'ner_match': ['blah', 'blash'],\n",
       "  'fuzzy_matches':         query     match     score\n",
       "  0  blah blash   audible  0.687844\n",
       "  1  blah blash  doordash  0.774296\n",
       "  2  blah blash  doordash  0.774296\n",
       "  3  blah blash  snapchat  0.777177\n",
       "  4  blah blash    caviar  0.778069,\n",
       "  'matches_for_sentence': ['audible',\n",
       "   'doordash',\n",
       "   'audible',\n",
       "   'caviar',\n",
       "   'snapchat']},\n",
       " 'REG': {'ner_match': [], 'fuzzy_matches': None, 'matches_for_sentence': []},\n",
       " 'DATE': {'ner_match': [], 'fuzzy_matches': None, 'matches_for_sentence': []},\n",
       " 'PLAT': {'ner_match': [], 'fuzzy_matches': None, 'matches_for_sentence': []},\n",
       " 'MET': {'ner_match': ['apps reviews'],\n",
       "  'fuzzy_matches':           query                match     score    type\n",
       "  0  apps reviews              reviews  0.526014     app\n",
       "  1  apps reviews    top chart reviews  0.646233  market\n",
       "  2  apps reviews              ratings  0.683010     app\n",
       "  3  apps reviews  top chart downloads  0.688862  market\n",
       "  4  apps reviews            downloads  0.720671     app,\n",
       "  'matches_for_sentence': [('reviews', 'app'),\n",
       "   ('top chart reviews', 'market'),\n",
       "   ('top chart reviews', 'market'),\n",
       "   ('reviews', 'app'),\n",
       "   ('top chart downloads', 'market')]},\n",
       " 'CAT': {'ner_match': [], 'fuzzy_matches': None, 'matches_for_sentence': []}}"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "5b5fff02-caf3-4d73-ae41-7ef9ba6ed1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APP': {'ner_match': ['facebook'],\n",
       "  'fuzzy_matches':       query               match         score\n",
       "  0  facebook            facebook  6.376011e-13\n",
       "  1  facebook  facebook messenger  2.701812e-01\n",
       "  2  facebook           messenger  6.388313e-01\n",
       "  3  facebook        youtube kids  6.431609e-01\n",
       "  4  facebook             youtube  6.466601e-01,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b11a208>,\n",
       "  'matches_for_sentence': ['facebook',\n",
       "   'facebook messenger',\n",
       "   'youtube',\n",
       "   'messenger',\n",
       "   'facebook']},\n",
       " 'REG': {'ner_match': ['uk'],\n",
       "  'fuzzy_matches':   query           match         score\n",
       "  0    uk              uk  6.382672e-13\n",
       "  1    uk  united kingdom  2.337332e-01\n",
       "  2    uk   great britain  3.025736e-01\n",
       "  3    uk       australia  5.053589e-01\n",
       "  4    uk             usa  5.859149e-01,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b994438>,\n",
       "  'matches_for_sentence': ['uk', 'uk', 'uk', 'uk', 'uk']},\n",
       " 'DATE': {'ner_match': [],\n",
       "  'fuzzy_matches': None,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b7642b0>,\n",
       "  'matches_for_sentence': [None]},\n",
       " 'PLAT': {'ner_match': [],\n",
       "  'fuzzy_matches':   query          match     score\n",
       "  0                apple  0.690785\n",
       "  1              android  0.749849\n",
       "  2                  ios  0.843035\n",
       "  3        android score  0.849106\n",
       "  4         google store  0.852993,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b764208>,\n",
       "  'matches_for_sentence': ['apple', 'android', 'android', 'apple', 'apple']},\n",
       " 'MET': {'ner_match': ['top', 'chart ranks', 'downloads'],\n",
       "  'fuzzy_matches':                        query                match     score\n",
       "  0  top chart ranks downloads  top chart downloads  0.187127\n",
       "  1  top chart ranks downloads      top chart ranks  0.206899\n",
       "  2  top chart ranks downloads      top chart users  0.297221\n",
       "  3  top chart ranks downloads    top chart revenue  0.323147\n",
       "  4  top chart ranks downloads    top chart reviews  0.342701,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b0e3f60>,\n",
       "  'matches_for_sentence': ['top chart downloads',\n",
       "   'top chart users',\n",
       "   'top chart reviews',\n",
       "   'top chart users',\n",
       "   'top chart reviews']},\n",
       " 'CAT': {'ner_match': [],\n",
       "  'fuzzy_matches':   query     match     score\n",
       "  0            news  0.538193\n",
       "  1          social  0.559366\n",
       "  2           media  0.568698\n",
       "  3        delivery  0.597077\n",
       "  4          gaming  0.624944,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b0e2c88>,\n",
       "  'matches_for_sentence': ['news', 'delivery', 'news', 'news', 'gaming']}}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "262174e3-667b-41ce-8db1-3115a8d531f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = 'class RandomMatchSelector(object):\\n    \\n    def __init__(self,ent_type=\"APP\",matcher_frame):\\n        \\n        probs = 1 - np.array(matcher_frame[\"score\"])\\n        self.probs = probs/np.max(probs)\\n        self.match_list = matcher_frame[\"fuzzy_matches\"].tolist()\\n    \\n    def return_matches(self,ndraws=5):\\n        \\n        return np.random.choice(self.match_list,size=ndraws,replace=True,p=self.probs)\\n        \\n    '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "a14cdb32-bf77-425d-bba2-1a8aa8ad9011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class RandomMatchSelector(object):\n",
      "    \n",
      "    def __init__(self,ent_type=\"APP\",matcher_frame):\n",
      "        \n",
      "        probs = 1 - np.array(matcher_frame[\"score\"])\n",
      "        self.probs = probs/np.max(probs)\n",
      "        self.match_list = matcher_frame[\"fuzzy_matches\"].tolist()\n",
      "    \n",
      "    def return_matches(self,ndraws=5):\n",
      "        \n",
      "        return np.random.choice(self.match_list,size=ndraws,replace=True,p=self.probs)\n",
      "        \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(vv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4be505-4e83-4d82-b1ea-daa23b417d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
