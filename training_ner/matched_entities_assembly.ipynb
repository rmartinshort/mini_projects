{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04b40c6-498f-44d6-8c23-98d413bd46f1",
   "metadata": {},
   "source": [
    "## Model to do\n",
    "\n",
    "- Try to build a model that handles the word splits better\n",
    "- Build a simple matcher that generates example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eea7bfcc-963a-44ac-b1f5-7df2507bbdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48f740d0-3489-41aa-9b66-690b8eb661eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    \n",
    "    def __init__(self, model_name = \"paraphrase-albert-small-v2\"):\n",
    "        \n",
    "        self.model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def vectorize_list(self, input_list):\n",
    "        \n",
    "        embedding_matrix = self.model.encode(input_list)\n",
    "        \n",
    "        return embedding_matrix\n",
    "    \n",
    "    def vectorize_single(self, input_string):\n",
    "        \n",
    "        embedding_vector = self.model.encode([input_string])\n",
    "        \n",
    "        return embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fabd6a78-196f-4b85-bc23-18953b3eab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-case-finetuned-app-ner\")\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-case-finetuned-app-ner-tok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9bb7accf-95dd-411b-b9ad-e26a5c467b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_dict = loaded_model.config.id2label\n",
    "label2id_dict = loaded_model.config.label2id\n",
    "model_label_2_id = {v:k for k,v in id2label_dict.items()}\n",
    "model_id_2_label = {v:k for k,v in label2id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b252bfac-44fe-4f64-82aa-999d1019130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_pipe = pipeline(\"ner\", aggregation_strategy=\"max\", model=loaded_model,tokenizer=loaded_tokenizer)\n",
    "feature_pipe = pipeline(\"feature-extraction\", model=loaded_model,tokenizer=loaded_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "075e1b9e-5ae9-4501-aa92-b44176a54173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matching_dictionary(matcher, DATA_PATH = \"data\"):\n",
    "    \n",
    "    matching_dict = {\"APP\":{},\"CAT\":{},\"PLAT\":{},\"REG\":{},\"MET\":{}}\n",
    "    \n",
    "    app_matcher = pd.read_csv(os.path.join(DATA_PATH,\"app_matching.csv\"))\n",
    "    matching_phrases = app_matcher[\"matching_phrase\"].tolist()\n",
    "    app_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"APP\"][\"embedding\"] = app_embedding_matrix\n",
    "    matching_dict[\"APP\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    metric_matcher = pd.read_csv(os.path.join(DATA_PATH,\"metric_matching.csv\"))\n",
    "    matching_phrases = metric_matcher[\"metric_name\"].tolist()\n",
    "    matching_type = metric_matcher[\"metric_type\"].tolist()\n",
    "    metric_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"MET\"][\"embedding\"] = metric_embedding_matrix\n",
    "    matching_dict[\"MET\"][\"matching_list\"] = matching_phrases\n",
    "    matching_dict[\"MET\"][\"metric_type\"] = matching_type\n",
    "    \n",
    "    platform_matcher = pd.read_csv(os.path.join(DATA_PATH,\"platform_matching.csv\"))\n",
    "    matching_phrases = platform_matcher[\"matching_phrase\"].tolist()\n",
    "    platform_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"PLAT\"][\"embedding\"] = platform_embedding_matrix\n",
    "    matching_dict[\"PLAT\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    region_matcher = pd.read_csv(os.path.join(DATA_PATH,\"region_matching.csv\"))\n",
    "    matching_phrases = region_matcher[\"matching_phrase\"].tolist()\n",
    "    region_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"REG\"][\"embedding\"] = region_embedding_matrix\n",
    "    matching_dict[\"REG\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    category_matcher = pd.read_csv(os.path.join(DATA_PATH,\"category_matching.csv\"))\n",
    "    matching_phrases = category_matcher[\"matching_phrase\"].tolist()\n",
    "    category_embedding_matrix = matcher.vectorize_list(matching_phrases)\n",
    "    \n",
    "    matching_dict[\"CAT\"][\"embedding\"] = category_embedding_matrix\n",
    "    matching_dict[\"CAT\"][\"matching_list\"] = matching_phrases\n",
    "    \n",
    "    return matching_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8fb0b60d-3c4a-4423-8d59-5eadb55a8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8cfe8d6-619d-417f-be07-aa91a3e1c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_dict = generate_matching_dictionary(matcher,DATA_PATH=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "eec05735-d8dc-4a56-a3b9-eed622b2b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_example_sentences(input_sentence,all_matches,vectorizer,nmatch=5):\n",
    "    \n",
    "    sentences = {}\n",
    "    for sent_id in range(nmatch):\n",
    "        sent = ''\n",
    "        sent_comps = {}\n",
    "        for ent_id, key in all_matches.items():\n",
    "            if len(key[\"ner_match\"]) > 0:\n",
    "                sent_comp = key[\"matches_for_sentence\"][sent_id]\n",
    "                sent_comps[ent_id] = sent_comp\n",
    "                sent += sent_comp\n",
    "                sent += \" \"\n",
    "        sent = sent.strip()\n",
    "        sentences[sent] = sent_comps\n",
    "        \n",
    "    matched_sentences_embedding = vectorizer.vectorize_list(list(sentences.keys()))\n",
    "    input_sentence_embedding = vectorizer.vectorize_single(input_sentence)\n",
    "    sentence_ordering = np.argsort(distance.cdist(input_sentence_embedding,matched_sentences_embedding,metric=\"cosine\")[0])\n",
    "    \n",
    "    return sentences, [list(sentences.keys())[i] for i in sentence_ordering]\n",
    "\n",
    "def extract_entities(model_output):\n",
    "\n",
    "    ents_data = {\"APP\":[],\"REG\":[],\"DATE\":[],\"PLAT\":[],\"MET\":[],\"CAT\":[]}\n",
    "    for ent in model_output[0]:\n",
    "        ent_id = model_label_2_id[ent['entity_group']]\n",
    "        ent_label = model_id_2_label[ent_id]\n",
    "    \n",
    "        if \"-\" in ent_label:\n",
    "            ent_label = ent_label.split(\"-\")[1]\n",
    "            ents_data[ent_label].append(ent[\"word\"])\n",
    "    \n",
    "    return ents_data\n",
    "\n",
    "\n",
    "def get_top_matches_to_ent(ents,match_dict,ent_type,nmatch=5):\n",
    "    \n",
    "    assert ent_type in [\"APP\", \"MET\", \"CAT\", \"REG\", \"PLAT\",\"DATE\"]\n",
    "    \n",
    "    if ent_type not in matching_dict:\n",
    "        return None\n",
    "    \n",
    "    # Doesn't work will for typos - need to use the ngram char matcher instead\n",
    "    # from the autocomplete matcher\n",
    "    \n",
    "    matched_ent = \" \".join(ents[ent_type])\n",
    "    matching_vector = matcher.vectorize_single(matched_ent)\n",
    "    distances = distance.cdist(matching_vector,matching_dict[ent_type][\"embedding\"],metric=\"cosine\")[0]\n",
    "    sorted_distances = np.argsort(distances)[:nmatch]\n",
    "    closest_matches = [matching_dict[ent_type][\"matching_list\"][i] for i in sorted_distances]\n",
    "    matched_df = pd.DataFrame({\"query\":[matched_ent]*nmatch,\"match\":closest_matches,\"score\":distances[sorted_distances]})\n",
    "    \n",
    "    return matched_df\n",
    "\n",
    "def get_matches(ents_data,match_dict):\n",
    "    \n",
    "    ents_matched_dict = {\"APP\":None,\"REG\":None,\"DATE\":None,\"PLAT\":None,\"MET\":None,\"CAT\":None}\n",
    "    \n",
    "    for ent, matches in ents_data.items():\n",
    "        \n",
    "        matched_ents = get_top_matches_to_ent(ents_data,match_dict=matching_dict,ent_type=ent)\n",
    "        match_selector = RandomMatchSelector(ent,matched_ents)\n",
    "        chosen_matches_for_sentence = match_selector.return_matches()\n",
    "        ents_matched_dict[ent] = {\"ner_match\":matches, \"fuzzy_matches\":matched_ents, \"match_selector\":match_selector, \"matches_for_sentence\":chosen_matches_for_sentence}\n",
    "    \n",
    "    return ents_matched_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cd6f5150-95ce-4544-ac1c-3fb44f35d0d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmartinshort/Documents/coding_experiments/image_similarity/image_search/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:214] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "query = \"the top chart ranks in uk\"\n",
    "# Get NER ents\n",
    "op = ner_pipe([query])\n",
    "# Extract thaen from the model output\n",
    "ents = extract_entities(op)\n",
    "# matches dictionary and their fuzzy matches\n",
    "all_matches = get_matches(ents,match_dict=matching_dict)\n",
    "# generate example sentences and then rank them - these will be the final matches\n",
    "sentences_map, ordered_sentences = construct_example_sentences(query,all_matches,vectorizer=matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "877df891-c7d6-45a8-9978-7e61b90c7dba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APP': {'ner_match': [],\n",
       "  'fuzzy_matches':   query      match     score\n",
       "  0              bbc  0.571618\n",
       "  1             bing  0.571880\n",
       "  2         bbc news  0.582875\n",
       "  3         cbc news  0.616941\n",
       "  4        economist  0.622728,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b0cb048>,\n",
       "  'matches_for_sentence': ['bbc', 'bbc', 'bbc news', 'bing', 'economist']},\n",
       " 'REG': {'ner_match': ['uk'],\n",
       "  'fuzzy_matches':   query           match         score\n",
       "  0    uk              uk  6.382672e-13\n",
       "  1    uk  united kingdom  2.337332e-01\n",
       "  2    uk   great britain  3.025736e-01\n",
       "  3    uk       australia  5.053589e-01\n",
       "  4    uk             usa  5.859149e-01,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b511048>,\n",
       "  'matches_for_sentence': ['uk', 'australia', 'uk', 'uk', 'united kingdom']},\n",
       " 'DATE': {'ner_match': [],\n",
       "  'fuzzy_matches': None,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b5114e0>,\n",
       "  'matches_for_sentence': [None]},\n",
       " 'PLAT': {'ner_match': [],\n",
       "  'fuzzy_matches':   query          match     score\n",
       "  0                apple  0.690785\n",
       "  1              android  0.749849\n",
       "  2                  ios  0.843035\n",
       "  3        android score  0.849106\n",
       "  4         google store  0.852993,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b511198>,\n",
       "  'matches_for_sentence': ['apple',\n",
       "   'android',\n",
       "   'apple',\n",
       "   'google store',\n",
       "   'ios']},\n",
       " 'MET': {'ner_match': ['top', 'chart ranks'],\n",
       "  'fuzzy_matches':              query                match         score\n",
       "  0  top chart ranks      top chart ranks  6.250556e-13\n",
       "  1  top chart ranks      top chart users  2.394876e-01\n",
       "  2  top chart ranks    top chart reviews  2.666774e-01\n",
       "  3  top chart ranks    top chart revenue  3.042744e-01\n",
       "  4  top chart ranks  top chart downloads  3.642268e-01,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b7e4cf8>,\n",
       "  'matches_for_sentence': ['top chart ranks',\n",
       "   'top chart downloads',\n",
       "   'top chart ranks',\n",
       "   'top chart reviews',\n",
       "   'top chart ranks']},\n",
       " 'CAT': {'ner_match': [],\n",
       "  'fuzzy_matches':   query     match     score\n",
       "  0            news  0.538193\n",
       "  1          social  0.559366\n",
       "  2           media  0.568698\n",
       "  3        delivery  0.597077\n",
       "  4          gaming  0.624944,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b9ad8d0>,\n",
       "  'matches_for_sentence': ['news', 'news', 'news', 'media', 'social']}}"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9bec8b7d-ee7e-4f1b-932c-08ee983f6880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uk top chart ranks',\n",
       " 'united kingdom top chart ranks',\n",
       " 'uk top chart reviews',\n",
       " 'australia top chart downloads']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5b5fff02-caf3-4d73-ae41-7ef9ba6ed1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'APP': {'ner_match': [],\n",
       "  'fuzzy_matches':   query      match     score\n",
       "  0              bbc  0.571618\n",
       "  1             bing  0.571880\n",
       "  2         bbc news  0.582875\n",
       "  3         cbc news  0.616941\n",
       "  4        economist  0.622728,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b0cb048>,\n",
       "  'matches_for_sentence': ['bbc', 'bbc', 'bbc news', 'bing', 'economist']},\n",
       " 'REG': {'ner_match': ['uk'],\n",
       "  'fuzzy_matches':   query           match         score\n",
       "  0    uk              uk  6.382672e-13\n",
       "  1    uk  united kingdom  2.337332e-01\n",
       "  2    uk   great britain  3.025736e-01\n",
       "  3    uk       australia  5.053589e-01\n",
       "  4    uk             usa  5.859149e-01,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b511048>,\n",
       "  'matches_for_sentence': ['uk', 'australia', 'uk', 'uk', 'united kingdom']},\n",
       " 'DATE': {'ner_match': [],\n",
       "  'fuzzy_matches': None,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b5114e0>,\n",
       "  'matches_for_sentence': [None]},\n",
       " 'PLAT': {'ner_match': [],\n",
       "  'fuzzy_matches':   query          match     score\n",
       "  0                apple  0.690785\n",
       "  1              android  0.749849\n",
       "  2                  ios  0.843035\n",
       "  3        android score  0.849106\n",
       "  4         google store  0.852993,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b511198>,\n",
       "  'matches_for_sentence': ['apple',\n",
       "   'android',\n",
       "   'apple',\n",
       "   'google store',\n",
       "   'ios']},\n",
       " 'MET': {'ner_match': ['top', 'chart ranks'],\n",
       "  'fuzzy_matches':              query                match         score\n",
       "  0  top chart ranks      top chart ranks  6.250556e-13\n",
       "  1  top chart ranks      top chart users  2.394876e-01\n",
       "  2  top chart ranks    top chart reviews  2.666774e-01\n",
       "  3  top chart ranks    top chart revenue  3.042744e-01\n",
       "  4  top chart ranks  top chart downloads  3.642268e-01,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b7e4cf8>,\n",
       "  'matches_for_sentence': ['top chart ranks',\n",
       "   'top chart downloads',\n",
       "   'top chart ranks',\n",
       "   'top chart reviews',\n",
       "   'top chart ranks']},\n",
       " 'CAT': {'ner_match': [],\n",
       "  'fuzzy_matches':   query     match     score\n",
       "  0            news  0.538193\n",
       "  1          social  0.559366\n",
       "  2           media  0.568698\n",
       "  3        delivery  0.597077\n",
       "  4          gaming  0.624944,\n",
       "  'match_selector': <__main__.RandomMatchSelector at 0x7f975b9ad8d0>,\n",
       "  'matches_for_sentence': ['news', 'news', 'news', 'media', 'social']}}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262174e3-667b-41ce-8db1-3115a8d531f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
