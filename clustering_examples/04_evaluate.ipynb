{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:14:22.900055Z",
     "start_time": "2018-04-04T17:14:22.890961Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-42931267712b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pyLDAvis.sklearn import prepare\n",
    "import pyLDAvis\n",
    "from wordcloud import WordCloud\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:14:22.930719Z",
     "start_time": "2018-04-04T17:14:22.905415Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# jtplot.style(theme='onedork', context='talk', fscale=1.4, spines=False, gridlines='--', ticks=True, grid=False, figsize=(14, 8))\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pyLDAvis.enable_notebook()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:15:44.963237Z",
     "start_time": "2018-04-04T17:15:43.912566Z"
    },
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "path = Path('bbc')\n",
    "files = path.glob('**/*.txt')\n",
    "doc_list = []\n",
    "for i, file in enumerate(files):\n",
    "    with open(str(file), encoding='latin1') as f:\n",
    "        _, topic, file_name = file.parts\n",
    "\n",
    "        lines = f.readlines()\n",
    "        file_id = file_name.split('.')[0]\n",
    "        heading = lines[0].strip()\n",
    "        body = ' '.join([l.strip() for l in lines[1:]])\n",
    "        doc_list.append([topic, heading, body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:15:50.959637Z",
     "start_time": "2018-04-04T17:15:50.795524Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(doc_list, columns=['topic', 'heading', 'article'])\n",
    "docs['word count'] = docs.article.str.split().str.len()\n",
    "docs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:15:50.969453Z",
     "start_time": "2018-04-04T17:15:50.963562Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "topic_labels = ['Topic {}'.format(i) for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:48.295690Z",
     "start_time": "2018-04-04T17:15:50.973237Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=.5, min_df=5, \n",
    "                             stop_words='english', \n",
    "                             max_features=2000)\n",
    "dtm = vectorizer.fit_transform(docs.article)\n",
    "lda = LatentDirichletAllocation(n_components=5, max_iter=500,\n",
    "                                learning_method='batch', \n",
    "                                evaluate_every=10, \n",
    "                                random_state=42)\n",
    "lda.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:51.319804Z",
     "start_time": "2018-04-04T17:17:48.303895Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "prepare(lda, dtm, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topics as WordClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:51.336909Z",
     "start_time": "2018-04-04T17:17:51.324525Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "topics_prob = lda.components_ / lda.components_.sum(axis=1).reshape(-1, 1)\n",
    "topics = pd.DataFrame(topics_prob.T,\n",
    "                      index=vectorizer.get_feature_names(),\n",
    "                      columns=topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:55.500826Z",
     "start_time": "2018-04-04T17:17:51.341522Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "w = WordCloud()\n",
    "fig, axes = plt.subplots(nrows=5, figsize=(15, 30))\n",
    "axes = axes.flatten()\n",
    "for t, (topic, freq) in enumerate(topics.items()):\n",
    "    w.generate_from_frequencies(freq.to_dict())\n",
    "    axes[t].imshow(w, interpolation='bilinear')\n",
    "    axes[t].set_title(topic, fontsize=18)\n",
    "    axes[t].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualize topic-word assocations per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:56.536651Z",
     "start_time": "2018-04-04T17:17:55.504374Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dtm_ = pd.DataFrame(data=lda.transform(dtm),\n",
    "                    columns=topic_labels,\n",
    "                    index=docs.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:56.547979Z",
     "start_time": "2018-04-04T17:17:56.540325Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "color_dict = OrderedDict()\n",
    "color_dict['Topic 1'] = {'color': 'white', 'on_color': 'on_blue'}\n",
    "color_dict['Topic 2'] = {'color': 'white', 'on_color': 'on_green'}\n",
    "color_dict['Topic 3'] = {'color': 'white', 'on_color': 'on_red'}\n",
    "color_dict['Topic 4'] = {'color': 'white', 'on_color': 'on_magenta'}\n",
    "color_dict['Topic 5'] = {'color': 'blue', 'on_color': 'on_yellow'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:56.595326Z",
     "start_time": "2018-04-04T17:17:56.553597Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dtm_['article'] = docs.article.values\n",
    "dtm_['heading'] = docs.heading.values\n",
    "sample = dtm_[dtm_[topic_labels].gt(.1).all(1)]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T17:17:56.671656Z",
     "start_time": "2018-04-04T17:17:56.599170Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "colored_text = []\n",
    "for word in sample.iloc[0, 5].split():\n",
    "    try:\n",
    "        topic = topics.loc[word.strip().lower()].idxmax()\n",
    "        colored_text.append(colored(word, **color_dict[topic]))\n",
    "    except:\n",
    "        colored_text.append(word)\n",
    "    \n",
    "\n",
    "print(' '.join([colored(k, **v) for k, v in color_dict.items()]))\n",
    "print('\\n',sample.iloc[0, 6], '\\n')\n",
    "text = ' '.join(colored_text)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
